{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info = pd.read_csv(\"dacon_data/building_info.csv\")\n",
    "train_df = pd.read_csv(\"dacon_data/train.csv\")\n",
    "test_df = pd.read_csv(\"dacon_data/test.csv\")\n",
    "sample_submission_df = pd.read_csv(\"dacon_data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"year\"] = train_df.apply(lambda x:int(x[\"일시\"].split(\" \")[0][:4]), axis=1)\n",
    "train_df[\"month\"] = train_df.apply(lambda x:int(x[\"일시\"].split(\" \")[0][4:6]), axis=1)\n",
    "train_df[\"day\"] = train_df.apply(lambda x:int(x[\"일시\"].split(\" \")[0][6:]), axis=1)\n",
    "train_df[\"hour\"] = train_df.apply(lambda x:int(x[\"일시\"].split(\" \")[1]), axis=1)\n",
    "train_df[\"date\"] = train_df.apply(lambda x:datetime(x[\"year\"], x[\"month\"], x[\"day\"]), axis=1)\n",
    "train_df[\"dow\"] = train_df.apply(lambda x:x[\"date\"].weekday(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"풍속(m/s)\"] = train_df[\"풍속(m/s)\"].interpolate()\n",
    "train_df[\"습도(%)\"] = train_df[\"습도(%)\"].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = dict()\n",
    "for i, type_ in enumerate(building_info[\"건물유형\"].unique()):\n",
    "    type_dict[type_] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info[\"type\"] = building_info.apply(lambda x:type_dict[x[\"건물유형\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df2 = pd.merge(train_df, building_info[[\"건물번호\", \"연면적(m2)\", \"냉방면적(m2)\", \"type\"]], on=\"건물번호\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2[\"area_norm\"] = np.log(train_df2[\"연면적(m2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2_train = train_df2[train_df2[\"date\"] < datetime(2022, 8, 1)]\n",
    "celcius_mean = train_df2_train[\"기온(C)\"].mean()\n",
    "celcius_std = train_df2_train[\"기온(C)\"].std()\n",
    "train_df2[\"celcius\"] = (train_df2[\"기온(C)\"] - celcius_mean) / celcius_std\n",
    "train_df2[\"humidity\"] = train_df2[\"습도(%)\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_no(date):\n",
    "    target = date\n",
    "    firstday = target.replace(day=1)\n",
    "    if firstday.weekday() == 6:\n",
    "        origin = firstday\n",
    "    elif firstday.weekday() < 3:\n",
    "        origin = firstday - timedelta(days=firstday.weekday() + 1)\n",
    "    else:\n",
    "        origin = firstday + timedelta(days=6 - firstday.weekday())\n",
    "    return (target - origin).days // 7 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2[\"week_num\"] = train_df2.apply(lambda x:get_week_no(x[\"date\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "2 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "3 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "4 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "5 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "6 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "7 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "8 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "9 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "10 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "11 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "12 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "13 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "14 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "15 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "16 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "17 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "18 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "19 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "20 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "21 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "22 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "23 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "24 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "25 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "26 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "27 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "28 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "29 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "30 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "31 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "32 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "33 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "34 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "35 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "36 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "37 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "38 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "39 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "40 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "41 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "42 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "43 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "44 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "45 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "46 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "47 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "48 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "49 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "50 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "51 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "52 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "53 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "54 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "55 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "56 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "57 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "58 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "59 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "60 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "61 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "62 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "63 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "64 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "65 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "66 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "67 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "68 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "69 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "70 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "71 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "72 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "73 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "74 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "75 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "76 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "77 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "78 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "79 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "80 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "81 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "82 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "83 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "84 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "85 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "86 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "87 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "88 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "89 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "90 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "91 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "92 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "93 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "94 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "95 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "96 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "97 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "98 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "99 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "100 x_size:(1, 336, 5), e_size:(1, 336, 5)\n",
      "train x_size:(96100, 336, 5), y_size:(96100, 168, 1), e_size:(96100, 336, 5)\n",
      "valid x_size:(40900, 336, 5), y_size:(40900, 168, 1), e_size:(40900, 336, 5)\n"
     ]
    }
   ],
   "source": [
    "value_features = [\"전력소비량(kWh)\", \"celcius\", \"humidity\", \"풍속(m/s)\", \"area_norm\"]\n",
    "cat_features = [\"week_num\", \"dow\", \"type\", \"hour\", \"건물번호\"]\n",
    "\n",
    "data_dir = \"dacon_train\"\n",
    "seq_len = 336\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "x_train_list, train_embedding_list, y_train_list = [], [], []\n",
    "x_valid_list, valid_embedding_list, y_valid_list = [], [], []\n",
    "test_dict = dict()\n",
    "\n",
    "x_offsets = np.sort(np.concatenate((np.arange(-(seq_len - 1), 1, 1),)))\n",
    "y_offsets = np.sort(np.arange(1, (168 + 1), 1))    \n",
    "\n",
    "for num in train_df2[\"건물번호\"].unique():\n",
    "    temp_dict = dict()\n",
    "    temp = train_df2[train_df2[\"건물번호\"] == num]\n",
    "    \n",
    "    test_df = temp.iloc[-seq_len:]\n",
    "    valid_df = temp[temp[\"date\"] >= (datetime(2022, 8, 1) - timedelta(days=14))]\n",
    "    train_df = temp[temp[\"date\"] < datetime(2022, 8, 1)]\n",
    "    \n",
    "    train_embedding_ = train_df[cat_features].values\n",
    "    train_value_ = train_df[value_features].values\n",
    "    \n",
    "    train_min_t = abs(min(x_offsets))\n",
    "    train_max_t = abs(len(train_value_)) - abs(max(y_offsets))\n",
    "    \n",
    "    for t in range(train_min_t, train_max_t):\n",
    "        x_train_list.append(train_value_[t + x_offsets, :])\n",
    "        train_embedding_list.append(train_embedding_[t + x_offsets, :])\n",
    "        y_train_list.append(train_value_[t + y_offsets, :1])\n",
    "        \n",
    "    valid_embedding_ = valid_df[cat_features].values\n",
    "    valid_value_ = valid_df[value_features].values\n",
    "    \n",
    "    valid_min_t = abs(min(x_offsets))\n",
    "    valid_max_t = abs(len(valid_value_)) - abs(max(y_offsets))\n",
    "    \n",
    "    for t in range(valid_min_t, valid_max_t):\n",
    "        x_valid_list.append(valid_value_[t + x_offsets, :])\n",
    "        valid_embedding_list.append(valid_embedding_[t + x_offsets, :])\n",
    "        y_valid_list.append(valid_value_[t + y_offsets, :1])\n",
    "        \n",
    "    test_embedding_ = test_df[cat_features].values\n",
    "    test_value_ = test_df[value_features].values\n",
    "    \n",
    "    test_min_t = abs(min(x_offsets))\n",
    "    test_max_t = abs(len(test_value_)) - abs(max(y_offsets))\n",
    "    \n",
    "    x_test = test_value_[x_offsets, :].reshape(-1, seq_len, len(value_features))\n",
    "    embedding_test = test_embedding_[x_offsets, :].reshape(-1, seq_len, len(cat_features))\n",
    "    \n",
    "    temp_dict[\"x\"] = x_test\n",
    "    temp_dict[\"e\"] = embedding_test\n",
    "    \n",
    "    print(f\"{num} x_size:{x_test.shape}, e_size:{embedding_test.shape}\")\n",
    "    test_dict[num] = temp_dict\n",
    "    \n",
    "\n",
    "x_train = np.stack(x_train_list, axis=0)\n",
    "y_train = np.stack(y_train_list, axis=0)\n",
    "embedding_train = np.stack(train_embedding_list, axis=0)\n",
    "\n",
    "np.savez_compressed(f\"{data_dir}/train.npz\", x=x_train, y=y_train, e=embedding_train)\n",
    "print(f\"train x_size:{x_train.shape}, y_size:{y_train.shape}, e_size:{embedding_train.shape}\")\n",
    "\n",
    "x_valid = np.stack(x_valid_list, axis=0)\n",
    "y_valid = np.stack(y_valid_list, axis=0)\n",
    "embedding_valid = np.stack(valid_embedding_list, axis=0)\n",
    "\n",
    "np.savez_compressed(f\"{data_dir}/valid.npz\", x=x_valid, y=y_valid, e=embedding_valid)\n",
    "print(f\"valid x_size:{x_valid.shape}, y_size:{y_valid.shape}, e_size:{embedding_valid.shape}\")\n",
    "\n",
    "with open(f\"{data_dir}/test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
